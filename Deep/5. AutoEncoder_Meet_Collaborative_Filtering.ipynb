{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjwjjwjjwjjwjjw/Recommender-System/blob/main/5.%20AutoEncoder_Meet_Collaborative_Filtering_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hRxU0XceJ7T"
      },
      "source": [
        "# AutoEncoder Meet Collaborative Filtering\n",
        "\n",
        "- Collaborative Filtering을 위해 user-item matrix 만들기\n",
        "- AutoEncoder 모델 구조 정의하기\n",
        "\n",
        "* Training Deep AutoEncoder 논문은 [저자 코드](https://github.com/NVIDIA/DeepRecommender) 참고"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXlMV8Y60jX"
      },
      "source": [
        "## 논문 종류\n",
        "- AutoRec\n",
        "- Training Deep AutoEncoder\n",
        "- Variational AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j33t09nr1cBy"
      },
      "source": [
        "## 1. Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hyvybxs2erv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5499e77-e12c-4b85-93e5-f4f34f1c0e4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/data/kmrd/kmr_dataset/datafile/kmrd-small'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjh9_2K42mr_"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VapCgQaG392F"
      },
      "source": [
        "def read_data(data_path):\n",
        "    df = pd.read_csv(os.path.join(data_path,'rates.csv'))[:10000]\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=1234, shuffle=True)\n",
        "\n",
        "    user_to_index = {original: idx for idx, original in enumerate(df.user.unique())}\n",
        "    movie_to_index = {original: idx for idx, original in enumerate(df.movie.unique())}\n",
        "\n",
        "    return train_df, val_df, user_to_index, movie_to_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQsVo6HT2zKl"
      },
      "source": [
        "class KMRDdataset(Dataset):\n",
        "    def __init__(self, df, user_to_index, movie_to_index, item_based=True):\n",
        "        self.min_rating = min(df.rate)\n",
        "        self.max_rating = max(df.rate)\n",
        "\n",
        "        self.user = [user_to_index[u] for u in df.user.values]\n",
        "        self.movie = [movie_to_index[m] for m in df.movie.values]\n",
        "        self.rating = df.rate.values\n",
        "\n",
        "        if item_based:\n",
        "          input_tensor = torch.LongTensor([self.movie, self.user])\n",
        "          self.data = torch.sparse.FloatTensor(input_tensor, torch.FloatTensor(self.rating),\n",
        "                                             torch.Size([len(movie_to_index), len(user_to_index)])).to_dense()\n",
        "        else:\n",
        "          input_tensor = torch.LongTensor([self.user, self.movie])\n",
        "          self.data = torch.sparse.FloatTensor(input_tensor, torch.FloatTensor(self.rating),\n",
        "                                             torch.Size([len(user_to_index), len(movie_to_index)])).to_dense()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.data[idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6PFQI_T4BWC"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/data/kmrd/kmr_dataset/datafile/kmrd-small'\n",
        "train_df, val_df, user_to_index, movie_to_index = read_data(data_path=data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg4kGTuA7EYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b2b95a-dbfd-483a-dabb-0204a998f10c"
      },
      "source": [
        "train_dataset = KMRDdataset(train_df, user_to_index, movie_to_index)\n",
        "val_dataset = KMRDdataset(val_df, user_to_index, movie_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-49f9b3635475>:12: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)\n",
            "  self.data = torch.sparse.FloatTensor(input_tensor, torch.FloatTensor(self.rating),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af7ltEfi8fvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9b378e-0d9d-4cac-849d-e12fa3cbfdba"
      },
      "source": [
        "print(train_df.shape)\n",
        "print(train_dataset.data[0].size())\n",
        "print(val_df.shape)\n",
        "print(val_dataset.data[0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 4)\n",
            "torch.Size([466])\n",
            "(2000, 4)\n",
            "torch.Size([466])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUbaBsqX9o-F",
        "outputId": "6ccbfa52-98d5-4187-a6c7-b2a77b3b698b"
      },
      "source": [
        "print(len(list(user_to_index.keys())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9cK9qRk9-cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab07ee1b-a01f-4831-d0a0-c598fb10c9e2"
      },
      "source": [
        "train_dataset.data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0., 27.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  8.,  9.,  0., 10.,  0.,  9.,  0.,  0.,\n",
              "         0.,  0.,  5.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  9.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0., 10.,  0.,  1.,  0.,  0.,  0., 10.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  8.,  0.,  0., 10.,  0.,  0., 10.,  0.,  0.,  0.,\n",
              "         0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0., 10.,  0.,  0.,\n",
              "         7.,  0.,  0.,  0.,  0.,  8.,  0.,  7.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 19.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  8.,  0.,\n",
              "        10.,  0.,  0., 10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 20.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 20.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0., 20.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdVN39PZ9KTW"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YAz1zC1enpT"
      },
      "source": [
        "## 2. Define AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIslGCBesxV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.init as weight_init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLB11LGtCqpc"
      },
      "source": [
        "class SimpleAutoEncoder(nn.Module):\n",
        "  def __init__(self, num_inputs, num_hiddens, kind='sigmoid', dropout=None):\n",
        "    super(SimpleAutoEncoder, self).__init__()\n",
        "    # encoder -> hidden -> decoder\n",
        "    # input -> hidden -> output\n",
        "    # input -> hidden : encoder\n",
        "    # hidden -> output = input : decoder\n",
        "    self.encoder = nn.Sequential(nn.Linear(num_inputs, num_hiddens), self.activation(kind))\n",
        "    self.decoder = nn.Sequential(nn.Linear(num_hiddens, num_inputs), self.activation(kind))\n",
        "\n",
        "  def activation(self, kind):\n",
        "    if kind == 'selu':\n",
        "      return nn.SELU()\n",
        "    elif kind == 'relu':\n",
        "      return nn.ReLU()\n",
        "    elif kind == 'relu6':\n",
        "      return nn.ReLU6()\n",
        "    elif kind == 'sigmoid':\n",
        "      return nn.Sigmoid()\n",
        "    elif kind == 'tanh':\n",
        "      return nn.Tanh()\n",
        "    elif kind == 'elu':\n",
        "      return nn.ELU()\n",
        "    elif kind == 'lrelu':\n",
        "      return nn.LeakyReLU()\n",
        "    elif kind == 'none':\n",
        "      return input\n",
        "    else:\n",
        "      raise ValueError('Unknown non-linearity type')\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.decoder(self.encoder(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB24ZmTNkX4Y"
      },
      "source": [
        "class DeepAutoEncoder(nn.Module):\n",
        "  def __init__(self, num_hiddens, num_layers, dropout=None, nn_type='diamond'):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    # input -> hidden -> output\n",
        "    # input -> hidden(10) -> ... -> hidden(10) -> output = input\n",
        "    self.encoder, self.decoder = self.generate_layers(num_hiddens, num_layers, dropout, nn_type)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.decoder(self.encoder(x))\n",
        "\n",
        "  def generate_layers(self, num_hiddens, num_layers, dropout=None, nn_type='diamond'):\n",
        "    # hidden layers -> [50, 25, 12, 6, 12, 25, 50], [100 50 100] -> 100, 50, 60, 50 100\n",
        "    if nn_type == 'diamond':\n",
        "      encoder_modules = []\n",
        "      decoder_modules = []\n",
        "\n",
        "      hidden_layers = []\n",
        "      temp = num_hiddens\n",
        "      for idx, x in enumerate(range(num_layers)):\n",
        "        if idx == 0:\n",
        "          hidden_layers.append(temp)\n",
        "        else:\n",
        "          hidden_layers.append(int(temp/2))\n",
        "        temp = temp/2\n",
        "      hidden_layers = [x for x in hidden_layers if x > 10]\n",
        "\n",
        "      # encoder\n",
        "      for idx, num_hidden in enumerate(hidden_layers):\n",
        "        if idx < len(hidden_layers)-1:\n",
        "          encoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
        "          encoder_modules.append(nn.Sigmoid())\n",
        "\n",
        "      # decoder\n",
        "      hidden_layers = list(reversed(hidden_layers))\n",
        "      for idx, num_hidden in enumerate(hidden_layers):\n",
        "        if idx < len(hidden_layers)-1:\n",
        "          decoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
        "          decoder_modules.append(nn.Identity())\n",
        "\n",
        "    # num_hidden = 50, num_layers = 3 ->  input_dim -> [50, 50, 50] -> output_dim = input_dim\n",
        "    elif nn_type == 'constant':\n",
        "      hidden_layers = [num_hiddens] * num_layers\n",
        "      for idx, enc in enumerate(hidden_layers):\n",
        "        if idx < num_layers-1:\n",
        "          encoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
        "          encoder_modules.append(nn.Sigmoid())\n",
        "          decoder_modules.append(nn.Linear(hidden_layers[idx], hidden_layers[idx+1], bias=True))\n",
        "          decoder_modules.append(nn.Identity())\n",
        "\n",
        "    if dropout is not None:\n",
        "      encoder_modules = [x for y in (encoder_modules[i:i+2] + [nn.Dropout(dropout)] * (i < len(encoder_modules) - 1)\n",
        "                          for i in range(0, len(encoder_modules), 2)) for x in y]\n",
        "      decoder_modules = [x for y in (decoder_modules[i:i+2] + [nn.Dropout(dropout)] * (i < len(decoder_modules) - 1)\n",
        "                          for i in range(0, len(decoder_modules), 2)) for x in y]\n",
        "\n",
        "    encoder = nn.Sequential(*encoder_modules)\n",
        "    decoder = nn.Sequential(*decoder_modules)\n",
        "\n",
        "    return encoder, decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs3Vhx329WWf"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yT4duFy9tKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f283c6f-f556-4627-a753-d86126d50f12"
      },
      "source": [
        "num_users = len(user_to_index.keys())\n",
        "num_movies = len(movie_to_index.keys())\n",
        "print(num_users, num_movies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "466 532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHRCKWme9orW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737683e8-c59d-436b-e46c-b38837450b91"
      },
      "source": [
        "model = SimpleAutoEncoder(num_inputs=num_users, num_hiddens=100, kind='selu')\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleAutoEncoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=466, out_features=100, bias=True)\n",
              "    (1): SELU()\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=466, bias=True)\n",
              "    (1): SELU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kaoj5YWz9jQ7"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNw873Wyxh3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39edfcd4-9b39-4647-e8bb-8400e0cc302f"
      },
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        torch.nn.init.zeros_(m.bias)\n",
        "\n",
        "model.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleAutoEncoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=466, out_features=100, bias=True)\n",
              "    (1): SELU()\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=466, bias=True)\n",
              "    (1): SELU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9z-ujtJG9jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12df4cf8-9c0d-479a-9913-0237af32b99b"
      },
      "source": [
        "train_dataset.data[0].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([466])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofyyZ2wfH7df"
      },
      "source": [
        "# NVIDIA Recommender System 참고\n",
        "def MSEloss(inputs, targets, size_average=False):\n",
        "  mask = targets != 0\n",
        "  num_ratings = torch.sum(mask.float())\n",
        "  criterion = nn.MSELoss(reduction='sum' if not size_average else 'mean')\n",
        "  return criterion(inputs * mask.float(), targets), Variable(torch.Tensor([1.0])) if size_average else num_ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSgwkLYZ-kkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a836d333-831d-48b0-f588-c747c68645bb"
      },
      "source": [
        "model.train()\n",
        "train_loss = 0\n",
        "for idx, batch in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = model(batch)\n",
        "    loss, num_ratings = MSEloss(pred, batch)\n",
        "    loss = torch.sqrt(loss / num_ratings)\n",
        "    loss.backward()\n",
        "    train_loss += loss.item()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(train_loss / (idx+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.798173904418945\n",
            "8.127339839935303\n",
            "7.928656101226807\n",
            "8.645669341087341\n",
            "8.627775096893311\n",
            "9.352740208307901\n",
            "9.017054012843541\n",
            "8.962779760360718\n",
            "8.72599098417494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "451VvDfaF_V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1128599a-39cc-4a07-bfd4-9a658bc285a0"
      },
      "source": [
        "model.eval()\n",
        "val_loss = 0\n",
        "with torch.no_grad():\n",
        "  for idx, batch in enumerate(val_dataloader):\n",
        "    pred = model(batch)\n",
        "    loss, num_ratings = MSEloss(pred, batch)\n",
        "    loss = torch.sqrt(loss / num_ratings)\n",
        "    val_loss += loss.item()\n",
        "\n",
        "    print(val_loss/(idx+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.777812957763672\n",
            "8.20762586593628\n",
            "7.975713888804118\n",
            "7.799915552139282\n",
            "7.849256324768066\n",
            "7.771078109741211\n",
            "8.004486628941127\n",
            "7.878074645996094\n",
            "7.8124584621853295\n",
            "7.935044860839843\n",
            "7.849205103787509\n",
            "7.8197741111119585\n",
            "7.799714858715351\n",
            "7.851579087121146\n",
            "7.8280155499776205\n",
            "7.8735853135585785\n",
            "7.868301728192498\n",
            "7.881757683224148\n",
            "7.898125748885305\n",
            "7.857614493370056\n",
            "7.821154935019357\n",
            "7.813850229436701\n",
            "7.797533657239831\n",
            "7.78110518058141\n",
            "7.779367733001709\n",
            "7.786569650356586\n",
            "7.783439724533646\n",
            "7.787746940340314\n",
            "7.803332098599138\n",
            "7.811766878763835\n",
            "7.819547314797679\n",
            "7.805103659629822\n",
            "7.786350264693752\n",
            "7.741296557819142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEesoy95Ldfk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
